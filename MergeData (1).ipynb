{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37f64688-2ffe-44d1-a05a-f1367c29d9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel, SequentialFeatureSelector\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from statsmodels.api import OLS, add_constant\n",
    "from statsmodels.formula.api import mixedlm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c20a3f8-19da-444a-9475-5b1eb4a6a652",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 16px; color: blue;\"> 可用函式 </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "085f56f5-67dc-4042-9abd-f444444438c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_all_columns(df):\n",
    "    df_cleaned = df.copy()\n",
    "    for col in df_cleaned.columns:\n",
    "        if pd.api.types.is_string_dtype(df_cleaned[col]) or df_cleaned[col].dtype == object:\n",
    "            df_cleaned[col] = df_cleaned[col].astype(str).str.strip()\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01d86563-3d80-4614-b5e4-0a56818df4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_na_and_blank(df):\n",
    "    result = {}\n",
    "    for col in df.columns:\n",
    "        na_count = df[col].isna().sum()\n",
    "        blank_count = 0\n",
    "        if df[col].dtype == object or pd.api.types.is_string_dtype(df[col]):\n",
    "            blank_count = df[col].astype(str).apply(lambda x: x.strip() == '').sum()\n",
    "        result[col] = {'na': na_count, 'blank_or_space': blank_count}\n",
    "    return pd.DataFrame(result).T\n",
    "\n",
    "# summary = count_na_and_blank(df_merge) \n",
    "# summary = summary[(summary['na'] > 0) | (summary['blank_or_space'] > 0)]\n",
    "# print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66946695-8e88-43ed-9ed8-22b7a6500dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zms2: 分出L1/2 -> L1 L2\n",
    "def split_layer_rows(df):\n",
    "    df_base = df.copy()\n",
    "\n",
    "    mask = (\n",
    "        (df_base['mtl_type'] == '基板') &\n",
    "        (df_base['layer_2'].str.contains('/')) &\n",
    "        (~df_base['layer_2'].str.contains('-')) &\n",
    "        (~df_base['layer_2'].str.contains('L0'))\n",
    "    )\n",
    "\n",
    "    # 不需拆分的資料保留\n",
    "    df_keep = df_base[~mask].copy()\n",
    "\n",
    "    # 要拆分的資料\n",
    "    df_split = df_base[mask].copy()\n",
    "\n",
    "    # 新資料列清單\n",
    "    expanded_rows = []\n",
    "\n",
    "    for _, row in df_split.iterrows():\n",
    "        try:\n",
    "            layer_range = row['layer_2'].replace('L', '')  # 去除 'L'\n",
    "            start, end = map(int, layer_range.split('/'))  # 拆成起始與結束層數\n",
    "            for i in range(start, end + 1):\n",
    "                new_row = row.copy()\n",
    "                new_row['layer_2'] = f'L{i}'\n",
    "                expanded_rows.append(new_row)\n",
    "        except:\n",
    "            continue  # 若轉換失敗則略過\n",
    "\n",
    "    # 合併原本資料 + 展開資料\n",
    "    df_result = pd.concat([df_keep, pd.DataFrame(expanded_rows)], ignore_index=True)\n",
    "\n",
    "    # 可選擇排序（若有需要）\n",
    "    # df_result = df_result.sort_values(by=['prod_nbr', 'item_nbr', 'layer_2'], ignore_index=True)\n",
    "\n",
    "    return df_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea9ce5fc-20f2-40ec-b37e-5531c2ce2435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_scaling(row):\n",
    "    panel_id = row['Part_nbr']\n",
    "    layer = row['d_Layer']\n",
    "    short_col = f\"{layer}_short\"\n",
    "    long_col = f\"{layer}_long\"\n",
    "\n",
    "    short_val = None\n",
    "    long_val = None\n",
    "\n",
    "    if panel_id in df_VAR_indexed.index and short_col in df_VAR.columns and long_col in df_VAR.columns:\n",
    "        matched_rows = df_VAR.loc[df_VAR['Panel_ID'] == panel_id]\n",
    "\n",
    "        # 找第一筆非 0 值的 row\n",
    "        matched_rows = matched_rows[(matched_rows[short_col] != 0) & (matched_rows[long_col] != 0)]\n",
    "\n",
    "        if not matched_rows.empty:\n",
    "            matched = matched_rows.iloc[0]\n",
    "            short_val = matched[short_col]\n",
    "            long_val = matched[long_col]\n",
    "\n",
    "    return pd.Series({'short': short_val, 'long': long_val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc96dd06-995b-4fbf-abb0-0e4dc6152849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_mtl_desc(desc):\n",
    "    # 去掉廠商名\n",
    "    desc = desc.split('+長春')[0].split('+南亞')[0].strip()\n",
    "\n",
    "    # 正則式（最廣泛泛化）\n",
    "    pattern = r\"\"\"\n",
    "        (?P<thickness>\\d+\\.\\d{2,3})mm          # 玻纖厚度\n",
    "        [_\\-]?\n",
    "        (?P<cu_cfg>(?:\\d+|H)/(?:\\d+|H)|H/H)     # 銅箔上下層結構\n",
    "        (?:-(?P<cu_type>[A-Z0-9\\-/]+))?         # 可選銅箔類型\n",
    "        (?:\\+(?P<glass_str>[\\dA-Z\\*\\+\\-]+))?    # 可選玻纖編碼（不拆）\n",
    "    \"\"\"\n",
    "\n",
    "    match = re.match(pattern, desc, re.VERBOSE)\n",
    "    if match:\n",
    "        cu_cfg = match.group(\"cu_cfg\")\n",
    "        cu_upper, cu_lower = '', ''\n",
    "        if '/' in cu_cfg:\n",
    "            cu_upper, cu_lower = cu_cfg.split('/')\n",
    "        else:\n",
    "            cu_upper = cu_lower = None\n",
    "\n",
    "        def convert_cu(val):\n",
    "            if val is None:\n",
    "                return None\n",
    "            if val.upper() == 'H':\n",
    "                return 0.5\n",
    "            try:\n",
    "                return float(val)\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "        return pd.Series({\n",
    "            'glass_fabric_thickness(mm)': float(match.group(\"thickness\")),\n",
    "            'use_cu_upper_thickness': convert_cu(cu_upper),\n",
    "            'use_cu_lower_thickness': convert_cu(cu_lower),\n",
    "            'use_cu_type': match.group(\"cu_type\"),\n",
    "            'glass_fabric_type': match.group(\"glass_str\"),\n",
    "            'parse_failed_desc': None\n",
    "        })\n",
    "\n",
    "    return pd.Series({\n",
    "        'glass_fabric_thickness(mm)': None,\n",
    "        'use_cu_upper_thickness': None,\n",
    "        'use_cu_lower_thickness': None,\n",
    "        'use_cu_type': None,\n",
    "        'glass_fabric_type': None,\n",
    "        'parse_failed_desc': desc\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4e22ee-6cc9-4183-b44a-e28508ad28b2",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 16px; color: blue;\"> SQL Server 連接配置 </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b77e639a-582a-47a7-af75-cba81ed58ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DM\n",
    "server = 'NTEMES\\MES'\n",
    "username = 'CHIAFU\\wilson_liu'\n",
    "database = 'IM'\n",
    "trusted_conn = 'yes'\n",
    "\n",
    "connection_string = f'DRIVER={{SQL Server}};SERVER={server};DATABASE={database};UID={username};Trusted_Connection={trusted_conn};'\n",
    "\n",
    "conn = pyodbc.connect(connection_string)\n",
    "\n",
    "# 殘銅\n",
    "server = 'nte403'\n",
    "username = 'CHIAFU\\wilson_liu'\n",
    "database = 'chiafu'\n",
    "trusted_conn = 'yes'\n",
    "\n",
    "connection2_string = f'DRIVER={{SQL Server}};SERVER={server};DATABASE={database};UID={username};Trusted_Connection={trusted_conn};'\n",
    "\n",
    "conn2 = pyodbc.connect(connection2_string)\n",
    "\n",
    "# 壓合程式\n",
    "server = 'nte403'\n",
    "username = 'CHIAFU\\wilson_liu'\n",
    "database = 'wwip'\n",
    "trusted_conn = 'yes'\n",
    "\n",
    "connection5_string = f'DRIVER={{SQL Server}};SERVER={server};DATABASE={database};UID={username};Trusted_Connection={trusted_conn};'\n",
    "\n",
    "conn5 = pyodbc.connect(connection5_string)\n",
    "\n",
    "# recipe\n",
    "server = 'nte403'\n",
    "username = 'CHIAFU\\wilson_liu'\n",
    "database = 'wwip'\n",
    "trusted_conn = 'yes'\n",
    "\n",
    "connection4_string = f'DRIVER={{SQL Server}};SERVER={server};DATABASE={database};UID={username};Trusted_Connection={trusted_conn};'\n",
    "\n",
    "conn4 = pyodbc.connect(connection4_string)\n",
    "\n",
    "# bsitemm\n",
    "server = 'nte403'\n",
    "username = 'CHIAFU\\wilson_liu'\n",
    "database = 'erp'\n",
    "trusted_conn = 'yes'\n",
    "\n",
    "connection3_string = f'DRIVER={{SQL Server}};SERVER={server};DATABASE={database};UID={username};Trusted_Connection={trusted_conn};'\n",
    "\n",
    "conn3 = pyodbc.connect(connection3_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86037268-8f6f-44d0-9be1-a8d514af70ba",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 16px; color: blue;\"> DM </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0efd3829-1842-4edb-bc69-98dc0a46812b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查詢資料 JOIN (用AVGX 和 AVGY)\n",
    "query_join_IM = '''\n",
    "SELECT \n",
    "    m.idx, \n",
    "    m.Part_nbr, \n",
    "    m.Lot_nbr, \n",
    "    m.Layer, \n",
    "    m.CamX, \n",
    "    m.CamY,\n",
    "    m.Credate,\n",
    "    d.Layer AS d_Layer,\n",
    "    d.PSVariationX AS d_PSVarX, \n",
    "    d.PSVariationY AS d_PSVarY,\n",
    "    d.AVGX,\n",
    "    d.AVGY,\n",
    "    s.kind\n",
    "FROM \n",
    "    DRY_XrayProduction_M m\n",
    "    \n",
    "LEFT JOIN \n",
    "    DRY_XrayProduction_D d ON m.idx = d.idx\n",
    "\n",
    "LEFT JOIN \n",
    "    nte403.chiafu.dbo.slss s ON m.Part_nbr = s.part_nbr\n",
    "WHERE \n",
    "    m.Credate > '2024-01-01' \n",
    "    AND NOT (m.Credate >= '2025-01-01' AND m.Credate <= '2025-05-26')\n",
    "'''\n",
    "# m.Layer = d.Layer 不會對應到 811S002A4GN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b44a96ec-1f00-4298-a0ea-f036399818a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wilson_liu\\AppData\\Local\\Temp\\ipykernel_9360\\1173620096.py:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_DM = pd.read_sql(query_join_IM, conn)\n"
     ]
    }
   ],
   "source": [
    "df_DM = pd.read_sql(query_join_IM, conn)\n",
    "df_DM = strip_all_columns(df_DM)\n",
    "df_DM = df_DM.drop(columns=['idx'])\n",
    "# df_DM = df_DM[df_DM['kind'] != 'N']\n",
    "df_DM = df_DM[df_DM['kind'] == 'I']\n",
    "df_DM = df_DM.drop(columns=['kind'])\n",
    "df_DM = df_DM.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e94a911-a4ff-47d3-8bb5-75738ec3a290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確保 Credate 是 datetime 格式\n",
    "df_DM['Credate'] = pd.to_datetime(df_DM['Credate'])\n",
    "\n",
    "# 找出每個 group 裡 Credate 最大的那一筆資料的 index\n",
    "idx = df_DM.groupby(['Part_nbr', 'Lot_nbr', 'Layer', 'd_Layer'])['Credate'].idxmax()\n",
    "\n",
    "# 選出這些資料\n",
    "df_DM = df_DM.loc[idx].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8eacc2-61bb-4e4d-b140-f142f28a035e",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 16px; color: blue;\">殘銅</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94b80ac4-c36b-45bd-8845-b19fdf64e69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wilson_liu\\AppData\\Local\\Temp\\ipykernel_9360\\2986971347.py:17: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_zms = pd.read_sql(query_join_zms, conn2)\n"
     ]
    }
   ],
   "source": [
    "# 查詢資料 JOIN 殘銅\n",
    "# 串入M 檔的料號，先串好，再挑時間\n",
    "\n",
    "query_join_zms = '''\n",
    "SELECT\n",
    "    a1.prod_nbr, a1.layer AS layer_full, a1.iss_x, a1.iss_y, a1.creat_date,\n",
    "    s6.it3, s6.it5, s6.layer\n",
    "FROM \n",
    "    zms1a a1\n",
    "INNER JOIN \n",
    "    zms6 s6\n",
    "    ON a1.prod_nbr = s6.prod_nbr AND a1.layer = s6.layer    \n",
    "WHERE \n",
    "    s6.cused='51' \n",
    "    AND a1.creat_date >= '2024-01-01' AND NOT ( a1.creat_date >= '2025-01-01' AND a1.creat_date <= '2025-05-26') \n",
    "'''\n",
    "df_zms = pd.read_sql(query_join_zms, conn2)\n",
    "df_zms =df_zms.sort_values(by='creat_date', ascending=False)\n",
    "df_zms = strip_all_columns(df_zms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cb63309-6ce7-4042-a6c2-353fc52aa85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'prod_nbr', 'layer_full' 若相同，留最新\n",
    "# 確保 creat_date 是 datetime 格式\n",
    "df_zms['creat_date'] = pd.to_datetime(df_zms['creat_date'])\n",
    "\n",
    "# 找出每個 group 裡 Credate 最大的那一筆資料的 index\n",
    "idx = df_zms.groupby(['prod_nbr', 'layer_full'])['creat_date'].idxmax()\n",
    "\n",
    "# 選出這些資料\n",
    "df_zms = df_zms.loc[idx].reset_index(drop=True)\n",
    "df_zms = df_zms.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6665886b-1862-46ab-a182-78870119e390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 層重複交疊問題\n",
    "# df_zms[df_zms['prod_nbr']=='395A024A33H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd914362-dc01-4381-a1aa-35dc024f2f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 轉回數字格式\n",
    "df_zms['it3'] = pd.to_numeric(df_zms['it3'], errors='coerce')\n",
    "df_zms['it5'] = pd.to_numeric(df_zms['it5'], errors='coerce')\n",
    "df_zms['iss_x'] = pd.to_numeric(df_zms['iss_x'], errors='coerce')\n",
    "df_zms['iss_y'] = pd.to_numeric(df_zms['iss_y'], errors='coerce')\n",
    "\n",
    "#  C面 / S面 殘銅率\n",
    "denominator = (df_zms['iss_x'] * df_zms['iss_y'] / 92903.04) + 0.001\n",
    "df_zms['C-Residual Copper Rate'] = df_zms['it3'] / denominator\n",
    "df_zms['S-Residual Copper Rate'] = df_zms['it5'] / denominator\n",
    "\n",
    "df_zms = df_zms[['prod_nbr', 'layer', 'C-Residual Copper Rate', 'S-Residual Copper Rate']]\n",
    "\n",
    "# df_zms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c9ee692-3887-480c-bcbb-9218b5444bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_residual_expanded = []\n",
    "\n",
    "for _, row in df_zms.iterrows():\n",
    "    layer_raw = str(row['layer']).replace(\" \", \"\").upper()  # 確保一致性\n",
    "    raw_parts = layer_raw.split(\"/\")  # e.g. ['L6', '7']\n",
    "\n",
    "    # 安全檢查：忽略非2層格式的資料（例如 1 層或超過2層）\n",
    "    if len(raw_parts) != 2:\n",
    "        continue\n",
    "\n",
    "    def normalize(layer_str):\n",
    "        m = re.search(r'\\d+', layer_str)\n",
    "        return f'L{m.group()}' if m else None\n",
    "\n",
    "    layer1 = normalize(raw_parts[0])\n",
    "    layer2 = normalize(raw_parts[1])\n",
    "    \n",
    "    if layer1 is None or layer2 is None:\n",
    "        continue  # 忽略格式錯誤的\n",
    "\n",
    "    df_residual_expanded.append({\n",
    "        'prod_nbr': row['prod_nbr'],\n",
    "        'd_Layer': layer1,\n",
    "        'Residual Copper Rate': row['C-Residual Copper Rate']\n",
    "    })\n",
    "    df_residual_expanded.append({\n",
    "        'prod_nbr': row['prod_nbr'],\n",
    "        'd_Layer': layer2,\n",
    "        'Residual Copper Rate': row['S-Residual Copper Rate']\n",
    "    })\n",
    "\n",
    "# 建立新的展平後的殘銅率表\n",
    "df_residual_flat = pd.DataFrame(df_residual_expanded)\n",
    "df_residual_flat = df_residual_flat.drop_duplicates()\n",
    "df_residual_flat = df_residual_flat.groupby(['prod_nbr', 'd_Layer'])['Residual Copper Rate'].mean().reset_index() # 取平均，處理層重複交疊問題"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c46f5a-69e4-40ec-8225-8d37daa004cd",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 16px; color: blue;\">壓合程式、壓合recipe</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd38030d-e177-4cfb-acb5-d562eff6d2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wilson_liu\\AppData\\Local\\Temp\\ipykernel_9360\\2726373186.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_cpinm = pd.read_sql(query_cpinm, conn5)\n"
     ]
    }
   ],
   "source": [
    "# df_cpinm( part_nbr、lot_nbr、layer) and credate -> df_DM_IM_zms ('Part_nbr', 'Lot_nbr', 'Layer')\n",
    "# df_cpinm(壓合recipe)-> RMS_PinlamRecipe (RecipeName)\n",
    "\n",
    "query_cpinm = \"SELECT macno as 'MacNo',in_code as 'MacRecipe' , * FROM cpinm WHERE credate >= '2024-01-01' AND NOT (credate >= '2025-01-01' AND credate <= '2025-05-26') \"\n",
    "\n",
    "df_cpinm = pd.read_sql(query_cpinm, conn5)\n",
    "df_cpinm = strip_all_columns(df_cpinm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6107d8a1-6ee2-4610-92f3-171b66fa9c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MacNo', 'MacRecipe', 'cpinnbr', 'cpin_pro', 'work_ctr', 'credate',\n",
       "       'shift', 'lot_nbr', 'part_nbr', 'ver', 'layer', 'macno', 'ssample',\n",
       "       'itemno', 'mtl_desc', 'cplot_nbr', 'qty', 'iopen', 'in_type', 'in_qty',\n",
       "       'kg', 'in_code', 'b_desc', 'in_time', 'memo', 'hdi', 'fail_qty',\n",
       "       'in_open', 'userid', 'lastdate', 'cdate', 'facekg', 'Outsourcing',\n",
       "       'Bonding', 'StackPN', 'ChkRecNbr', 'CarrierNo'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cpinm.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea10530f-7437-4e1e-b6c2-43159474db2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'prod_nbr', 'layer_full' 若相同，留最新\n",
    "# 確保 creat_date 是 datetime 格式\n",
    "df_cpinm['creat_date'] = pd.to_datetime(df_cpinm['credate'])\n",
    "\n",
    "# 找出每個 group 裡 Credate 最大的那一筆資料的 index\n",
    "idx = df_cpinm.groupby(['part_nbr', 'lot_nbr', 'layer'])['credate'].idxmax()\n",
    "\n",
    "# 選出這些資料\n",
    "df_cpinm = df_cpinm.loc[idx].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33480dfb-25a8-4afb-8f0b-c8e2c5d7d182",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cpinm = df_cpinm[['MacNo', 'MacRecipe', 'lot_nbr', 'layer', 'part_nbr']]\n",
    "df_cpinm = df_cpinm.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5acf068-4ee7-4bc2-bc09-a11b094dc046",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 16px; color: blue;\">RC、廠商和基板型號</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c88ee36-72d8-421a-98c6-039b4c2c4f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wilson_liu\\AppData\\Local\\Temp\\ipykernel_9360\\2876753893.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_zms2 = pd.read_sql(query_zms2, conn2)\n",
      "C:\\Users\\wilson_liu\\AppData\\Local\\Temp\\ipykernel_9360\\2876753893.py:8: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_zbom2 = pd.read_sql(query_zbom2, conn2)\n",
      "C:\\Users\\wilson_liu\\AppData\\Local\\Temp\\ipykernel_9360\\2876753893.py:12: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_bsitemm = pd.read_sql(query_bsitemm, conn3)\n"
     ]
    }
   ],
   "source": [
    "# 以下三個串 RC\n",
    "\n",
    "query_zms2 = \"SELECT * FROM zms2\"\n",
    "df_zms2 = pd.read_sql(query_zms2, conn2)\n",
    "df_zms2 = strip_all_columns(df_zms2)\n",
    "\n",
    "query_zbom2 = \"SELECT * FROM zbom2\"\n",
    "df_zbom2 = pd.read_sql(query_zbom2, conn2)\n",
    "df_zbom2 = strip_all_columns(df_zbom2)\n",
    "\n",
    "query_bsitemm = \"SELECT * FROM bsitemm\"\n",
    "df_bsitemm = pd.read_sql(query_bsitemm, conn3)\n",
    "df_bsitemm = strip_all_columns(df_bsitemm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2283a7fe-2f84-4086-8e28-2d06d60e39a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_RC = '''\n",
    "WITH step0 AS (\n",
    "    SELECT * \n",
    "    FROM (\n",
    "        SELECT *, RANK() OVER (PARTITION BY prod_nbr, mtl_type ORDER BY ver DESC) AS rk \n",
    "        FROM zbom2\n",
    "    ) t\n",
    "    WHERE rk = 1\n",
    "),step1 as(\n",
    "\tSELECT \n",
    "\t\ta.*, \n",
    "\t\tCOALESCE(b1.itemno_1, b2.itemno_1) AS itemno_1  -- 先對非基板，對完再對基板的部分\n",
    "\tFROM zms2 a\n",
    "\tLEFT JOIN step0 b1 \n",
    "\t\tON a.prod_nbr = b1.prod_nbr \n",
    "\t   AND a.layer = b1.layer \n",
    "\t   AND a.mtl_type = b1.mtl_type \n",
    "\t   AND a.item_nbr = b1.mtl_types\n",
    "\tLEFT JOIN step0 b2 \n",
    "\t\tON a.prod_nbr = b2.prod_nbr \n",
    "\t   AND a.layer_2 = b2.layer \n",
    "\t   AND a.mtl_type = b2.mtl_type \n",
    ")\n",
    "select a.*, b.itemcnm from step1 a\n",
    "left join erp..bsitemm b on a.itemno_1 = b.itemno\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdafbceb-0031-40dc-ae48-74074557cc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wilson_liu\\AppData\\Local\\Temp\\ipykernel_9360\\3902887923.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_RC = pd.read_sql(query_RC, conn2)\n"
     ]
    }
   ],
   "source": [
    "# df_zms2 = df_zms2.drop(columns=['mtl_desc3', 'grade', 'mtl_flag', 'use_qty', 'mtl_desc4', 'mtl_desc5', 'layer_2ThickTole']) # 去掉 mtl_desc3、grade，都是' '\n",
    "# df_zms2 = df_zms2.sort_values(by=['prod_nbr', 'layer', 'item_nbr', 'layer_2']).reset_index(drop=True)\n",
    "df_RC = pd.read_sql(query_RC, conn2)\n",
    "df_RC = strip_all_columns(df_RC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d2b4ed-fbb6-45d2-adc8-43506d78b01f",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 14px; color: green;\"> RC value</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b703fcc-a621-442a-ae0b-f4329cd48ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_RC[df_RC['prod_nbr'] == '366S938BA8C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08f7d17d-7905-4f0b-8e47-b1b65b4bfda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立新欄位 'RC_value' 的data: df_RC\n",
    "df_RC['RC_value'] = df_RC['itemcnm'].str.extract(r'RC[:\\s]?(\\d+)', expand=False)\n",
    "df_RC['RC_value'] = pd.to_numeric(df_RC['RC_value'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2433d20c-3f45-44b2-a251-ac2b68abc955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(237476)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_RC['RC_value'].notna().sum() # 237476"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661389be-9c07-4068-9cfe-d1330e0a7da8",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 12px; color: red;\"> df_RC 整理成 1 to 1</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80b2fff0-ec3f-4652-b837-a9e308f0c8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_RC[['prod_nbr', 'layer', 'item_nbr', 'mtl_type', 'mtl_desc1','mtl_desc2', 'vend_nbr', 'layer_2', 'layer_2Thick', 'RC_value']]\n",
    "x1 = split_layer_rows(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd708890-5ccd-4e36-ab56-3070570c70fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用df_DM篩選df_RC，為 df_RC_sub\n",
    "\n",
    "# 1. 把 df_merge 的key value組合取出來，轉成唯一列表\n",
    "key_pairs = (\n",
    "    df_DM[['Part_nbr', 'Layer']]\n",
    "    .drop_duplicates()\n",
    "    .rename(columns={'Part_nbr': 'prod_nbr', 'Layer': 'layer'})   # 改名方便後面 inner merge\n",
    ")\n",
    "\n",
    "# 2. 直接 inner merge，保留「兩邊共有」的 (prod_nbr, layer)\n",
    "x1_sub = (\n",
    "    x1\n",
    "      .merge(key_pairs, on=['prod_nbr', 'layer'], how='inner')\n",
    "      .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91286c41-3777-41bf-88f4-071f509d223b",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 12px; color: red;\"> check料號: 120SO07DA8C、999S790AB8G (這沒有RC)、107S002C48N、395A024A33H(沒銅箔)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b79b797-6989-4e39-96cc-bf2f9ab838fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預處理：保留原始索引\n",
    "df = x1_sub.sort_values(by=['prod_nbr', 'layer', 'item_nbr']).reset_index()\n",
    "\n",
    "# 初始化所有 plate_ 欄位\n",
    "cols_to_plate = [col for col in df.columns \n",
    "                if col not in ['prod_nbr', 'layer', 'item_nbr', 'mtl_type', 'index']]\n",
    "for col in cols_to_plate:\n",
    "    df[f'plate_{col}'] = None\n",
    "\n",
    "drop_indexes = []\n",
    "result_df = df.copy()\n",
    "\n",
    "# 處理每個 group\n",
    "for (prod, layer), group in df.groupby(['prod_nbr', 'layer']):\n",
    "    group = group.sort_values('item_nbr').reset_index(drop=True)\n",
    "    \n",
    "    # 找出所有非膠片的索引位置（基板或銅箔）\n",
    "    non_adhesive_indices = group[group['mtl_type'].isin(['基板', '銅箔'])].index.tolist()\n",
    "    \n",
    "    # 處理每兩個非膠片之間的膠片\n",
    "    for i in range(len(non_adhesive_indices)-1):\n",
    "        start_idx = non_adhesive_indices[i]\n",
    "        end_idx = non_adhesive_indices[i+1]\n",
    "        \n",
    "        # 取得區間內的膠片\n",
    "        adhesives = group.loc[start_idx+1:end_idx-1]\n",
    "        adhesives = adhesives[adhesives['mtl_type'] == '膠片'].sort_values('item_nbr')\n",
    "        \n",
    "        # 如果有膠片才處理\n",
    "        if len(adhesives) > 0:\n",
    "            prev_row = group.loc[start_idx]\n",
    "            next_row = group.loc[end_idx]\n",
    "\n",
    "            prev_idx = result_df[result_df['index'] == prev_row['index']].index[0]\n",
    "            next_idx = result_df[result_df['index'] == next_row['index']].index[0]\n",
    "\n",
    "            # 特殊情況：連續相同 item_nbr 的基板\n",
    "            if (prev_row['mtl_type'] == '基板' and next_row['mtl_type'] == '基板' and\n",
    "                prev_row['item_nbr'] == next_row['item_nbr']):\n",
    "                \n",
    "                # 將膠片按順序分配給連續基板\n",
    "                for k, (adhesive_idx, adhesive_row) in enumerate(adhesives.iterrows()):\n",
    "                    target_pos = start_idx + k\n",
    "                    if target_pos <= end_idx:\n",
    "                        target_row = group.loc[target_pos]\n",
    "                        target_df_idx = result_df[result_df['index'] == target_row['index']].index[0]\n",
    "                        for col in cols_to_plate:\n",
    "                            result_df.loc[target_df_idx, f'plate_{col}'] = adhesive_row[col]\n",
    "                        drop_indexes.append(adhesive_row['index'])\n",
    "            else:\n",
    "                if len(adhesives) == 1:\n",
    "                    # 單一膠片，複製兩次\n",
    "                    first_adhesive = adhesives.iloc[0]\n",
    "                    second_adhesive = adhesives.iloc[0]\n",
    "                elif len(adhesives) >= 2:\n",
    "                    # 保留第一與最後一片膠片\n",
    "                    first_adhesive = adhesives.iloc[0]\n",
    "                    second_adhesive = adhesives.iloc[-1]\n",
    "                    for j in range(1, len(adhesives)-1):\n",
    "                        drop_indexes.append(adhesives.iloc[j]['index'])\n",
    "\n",
    "                # 分配第一膠片給較近的那邊\n",
    "                first_dist_to_prev = abs(int(first_adhesive['item_nbr']) - int(prev_row['item_nbr']))\n",
    "                first_dist_to_next = abs(int(first_adhesive['item_nbr']) - int(next_row['item_nbr']))\n",
    "                first_target_idx = prev_idx if first_dist_to_prev <= first_dist_to_next else next_idx\n",
    "                for col in cols_to_plate:\n",
    "                    result_df.loc[first_target_idx, f'plate_{col}'] = first_adhesive[col]\n",
    "                drop_indexes.append(first_adhesive['index'])\n",
    "\n",
    "                # 分配第二膠片給另一邊\n",
    "                second_dist_to_prev = abs(int(second_adhesive['item_nbr']) - int(prev_row['item_nbr']))\n",
    "                second_dist_to_next = abs(int(second_adhesive['item_nbr']) - int(next_row['item_nbr']))\n",
    "                second_target_idx = next_idx if second_dist_to_next <= second_dist_to_prev else prev_idx\n",
    "                for col in cols_to_plate:\n",
    "                    result_df.loc[second_target_idx, f'plate_{col}'] = second_adhesive[col]\n",
    "                drop_indexes.append(second_adhesive['index'])\n",
    "\n",
    "# 刪除所有膠片\n",
    "x2 = result_df[~result_df['index'].isin(drop_indexes)].reset_index(drop=True)\n",
    "x2 = x2[x2['mtl_type'] != '膠片']\n",
    "\n",
    "# 可選：刪除完全為空的 plate_ 欄位\n",
    "x2 = x2.dropna(axis=1, how='all')\n",
    "x2 = x2.drop(columns=['index', 'plate_layer_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1fd5392-c95e-4fdf-99aa-15ead95bc031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x2 = x2.drop(columns=['index'])\n",
    "x2 = x2.rename(columns={'prod_nbr':'Part_nbr',\n",
    "                        'layer':'Layer',\n",
    "                        'layer_2':'d_Layer'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07965397-499e-428c-b88c-6101069e49cf",
   "metadata": {},
   "source": [
    "<p style=\"font_size:12; color:red;\">隨機抽取料號測試</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "feecda2f-b2a5-409d-a6c5-608b7905b575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_nbr = x2['Part_nbr'].unique()\n",
    "# random_nbr = random.choice(x2['Part_nbr'].unique())\n",
    "# random_nbr.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "96eca7ce-a041-4ad8-8831-e6c4f624a1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x2[x2['Part_nbr'] == '353S097B57F']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba00137-17cd-40f2-b779-b1e394d8cff3",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 14px; color: green;\"> 合併df_DM 和 x2(攤平膠片訊息與RC值)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4a6e021-3193-48c0-99f2-512d971f62a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge1 = df_DM.merge(\n",
    "    x2,\n",
    "    left_on=['Part_nbr', 'Layer', 'd_Layer'],\n",
    "    right_on=['Part_nbr', 'Layer', 'd_Layer'],\n",
    "    how='inner'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486e8d4f-1893-48e3-89a9-99efd1e7efb7",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 14px; color: green;\"> df_merge1 和 df_cpinm</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "239f5f3b-7156-4102-bae5-2508aada2a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cpinm = df_cpinm.rename(columns={'part_nbr':'Part_nbr',\n",
    "                              'layer':'Layer',\n",
    "                              'lot_nbr':'Lot_nbr'})\n",
    "\n",
    "df_merge2 = df_merge1.merge(\n",
    "    df_cpinm,\n",
    "    left_on=['Part_nbr', 'Lot_nbr', 'Layer'],\n",
    "    right_on=['Part_nbr', 'Lot_nbr', 'Layer'],\n",
    "    how='inner'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48220bc0-eb07-49f0-b506-d878eb077d9a",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 14px; color: green;\"> df_merge2 和 df_residual_flat(殘銅率)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b556be8-93b4-436d-b7cc-bfe090c60a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_residual_flat = df_residual_flat.rename(columns={'prod_nbr':'Part_nbr','d_Layer':'d_Layer'})\n",
    "\n",
    "df_merge3 = df_merge2.merge(\n",
    "     df_residual_flat,\n",
    "    left_on=['Part_nbr', 'd_Layer'],\n",
    "    right_on=['Part_nbr', 'd_Layer'],\n",
    "    how='inner'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "632c9c61-fc77-40b7-a430-322688a18112",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_merge3#[df_merge3['Part_nbr'] == '305E268C9BC'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b68323-0673-40f7-9137-c15b5e351ee1",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 16px; color: blue;\">內層帳縮</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd96f7d9-81dc-44ec-a8c9-4f5c620ae643",
   "metadata": {},
   "source": [
    "<p style = \"font_size: 16; color: blue;\"> 合併df_total and 內層漲縮值解析結果</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07cda1b0-373c-4d47-9bbc-f9d18ede723a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_VAR = pd.read_excel('內層漲縮值解析結果.xlsx')\n",
    "df_VAR = df_VAR.rename(columns={'Panel_ID':'Part_nbr'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d94b6890-dbf1-4ac0-aca9-a6ba680f2588",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.copy()\n",
    "x['Part_nbr'] = x['Part_nbr'].astype(str).str.strip()\n",
    "x['d_Layer'] = x['d_Layer'].astype(str).str.strip()\n",
    "df_VAR['Panel_ID'] = df_VAR['Part_nbr'].astype(str).str.strip()\n",
    "\n",
    "# 先把 df2 設為以 Panel_ID 為 index，方便查欄位\n",
    "df_VAR_indexed = df_VAR.set_index(\"Part_nbr\")\n",
    "\n",
    "# 套用\n",
    "x[['short', 'long']] = x.apply(get_layer_scaling, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12929370-9344-45ec-9cf6-5357ed7a23e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用df_VAR篩選x\n",
    "\n",
    "# 1. 把 df_VAR 的key value組合取出來，轉成唯一列表\n",
    "key_pairs = (\n",
    "    df_VAR[['Part_nbr']]\n",
    "    .drop_duplicates())   # 改名方便後面 inner merge\n",
    "\n",
    "# 2. 直接 inner merge，保留「兩邊共有」的 (Part_nbr)\n",
    "x = (\n",
    "    x.merge(key_pairs, on=['Part_nbr'], how='inner')\n",
    "      .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7fac77d8-8539-45f2-96a0-1a1b542ecdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = x#[x['Part_nbr']=='187S051A88C']\n",
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2fa6dd4-bf79-44dd-ab01-bf521f16604e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.drop(columns=['item_nbr', 'mtl_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcd104b-1805-4879-8838-380c7c7afadc",
   "metadata": {},
   "source": [
    "<p style = \"font_size: 16; color: blue;\">轉換欄位 mtl_desc1: parse_mtl_desc</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4564fb4b-c09e-403b-98e2-c533f30dc8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 轉換欄位 mtl_desc1: parse_mtl_desc\n",
    "parsed_df = a['mtl_desc1'].apply(parse_mtl_desc)\n",
    "parsed_df = parsed_df.rename(columns={'mtl_desc2':'substrate_thickness'})\n",
    "a_parsed = pd.concat([a, parsed_df], axis=1)\n",
    "# a_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e5e573f3-c736-4853-b3ec-d4ae36796b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_parsed = a_parsed[['Part_nbr', 'Lot_nbr', 'Layer', 'd_Layer', 'CamX', 'CamY', 'AVGX', 'AVGY', 'Credate', 'MacNo', 'MacRecipe',\n",
    "                     'mtl_desc1', 'mtl_desc2', 'vend_nbr', 'layer_2Thick', 'plate_mtl_desc1','plate_mtl_desc2', 'plate_vend_nbr', 'plate_layer_2Thick',\n",
    "                     'plate_RC_value','Residual Copper Rate','glass_fabric_thickness(mm)', 'use_cu_upper_thickness',\n",
    "                     'use_cu_lower_thickness', 'use_cu_type', 'glass_fabric_type', 'parse_failed_desc', 'short', 'long', 'd_PSVarX', 'd_PSVarY']]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ffd27b79-dc65-4822-b3dd-c58d5dc664f9",
   "metadata": {},
   "source": [
    "df_VAR 有為0的欄位(short、long)，原XML是0，下面會變NaN，如: 999S742B98C, 120SQ24AABC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6fdd2af0-edbb-4f44-8f6d-279974f7e12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57189, 31)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_parsed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6de273d-6204-4085-9d52-87f9e81934dd",
   "metadata": {},
   "source": [
    "<p style = \"font_size: 16; color: blue;\">測試 a_parsed</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "444428f0-27ab-4c22-b693-7ce1afbe4275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 Nan in Part_nbr.\n",
      "There are 0 Nan in Lot_nbr.\n",
      "There are 0 Nan in Layer.\n",
      "There are 0 Nan in d_Layer.\n",
      "There are 0 Nan in CamX.\n",
      "There are 0 Nan in CamY.\n",
      "There are 0 Nan in AVGX.\n",
      "There are 0 Nan in AVGY.\n",
      "There are 0 Nan in Credate.\n",
      "There are 0 Nan in MacNo.\n",
      "There are 0 Nan in MacRecipe.\n",
      "There are 0 Nan in mtl_desc1.\n",
      "There are 0 Nan in mtl_desc2.\n",
      "There are 0 Nan in vend_nbr.\n",
      "There are 0 Nan in layer_2Thick.\n",
      "There are 0 Nan in plate_mtl_desc1.\n",
      "There are 0 Nan in plate_mtl_desc2.\n",
      "There are 0 Nan in plate_vend_nbr.\n",
      "There are 0 Nan in plate_layer_2Thick.\n",
      "There are 5965 Nan in plate_RC_value.\n",
      "There are 0 Nan in Residual Copper Rate.\n",
      "There are 786 Nan in glass_fabric_thickness(mm).\n",
      "There are 786 Nan in use_cu_upper_thickness.\n",
      "There are 786 Nan in use_cu_lower_thickness.\n",
      "There are 1417 Nan in use_cu_type.\n",
      "There are 1819 Nan in glass_fabric_type.\n",
      "There are 56403 Nan in parse_failed_desc.\n",
      "There are 3653 Nan in short.\n",
      "There are 3653 Nan in long.\n",
      "There are 0 Nan in d_PSVarX.\n",
      "There are 0 Nan in d_PSVarY.\n"
     ]
    }
   ],
   "source": [
    "a_parsed = a_parsed.copy()\n",
    "a_parsed.replace(' ', np.nan, inplace=True)\n",
    "\n",
    "for col in a_parsed.columns:\n",
    "    nan_count = a_parsed[col].isna().sum()\n",
    "    print(f\"There are {nan_count} Nan in {col}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c77c3d1f-582b-411e-ad3c-9f443dfc87a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_parsed.to_excel('df_total.xlsx', index=False) # , na_rep='NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0ecafab2-4965-40ef-8406-13410550c7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_parsed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ce1f213c-a082-48d1-b3b7-f9fe3f7ff667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 無完全重複的組合\n"
     ]
    }
   ],
   "source": [
    "# 檢查完全重複的行\n",
    "duplicates = a_parsed.duplicated(subset=['Part_nbr', 'Lot_nbr', 'Layer', 'd_Layer'], keep=False)\n",
    "duplicated_rows = a_parsed[duplicates].sort_values(['Part_nbr', 'Lot_nbr'])\n",
    "\n",
    "if duplicated_rows.empty:\n",
    "    print(\"✅ 無完全重複的組合\")\n",
    "else:\n",
    "    print(f\"⚠️ 發現 {len(duplicated_rows)} 筆重複記錄：\")\n",
    "    # display(duplicated_rows.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f3cac58-00c3-4f48-b23b-01f955890ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 所有 (Part_nbr, Lot_nbr, Layer, d_Layer) 組合唯一\n"
     ]
    }
   ],
   "source": [
    "# 檢查是否唯一\n",
    "dupes = a_parsed[a_parsed.duplicated(subset=['Part_nbr', 'Lot_nbr', 'Layer', 'd_Layer'], keep=False)]\n",
    "if not dupes.empty:\n",
    "    print(\"❗ 有重複的組合：\")\n",
    "    display(dupes)\n",
    "else:\n",
    "    print(\"✅ 所有 (Part_nbr, Lot_nbr, Layer, d_Layer) 組合唯一\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cc29b50d-9b75-4ac1-92ee-f74e663797f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e = a_parsed.drop(columns=['MacNo','MacRecipe'])\n",
    "# # e['Credate'] = pd.to_datetime(e['Credate']).dt.date\n",
    "# e = e.drop_duplicates()\n",
    "# e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "43c06bdb-dad2-45e2-82d4-0f3338e4df57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 檢查完全重複的行\n",
    "# duplicates = e.duplicated(subset=['Part_nbr', 'Lot_nbr', 'Layer', 'd_Layer'], keep=False)\n",
    "# duplicated_rows = e[duplicates].sort_values(['Part_nbr', 'Lot_nbr'])\n",
    "# # duplicated_rows = duplicated_rows[duplicated_rows['Part_nbr']=='187S051A88C']\n",
    "\n",
    "# if duplicated_rows.empty:\n",
    "#     print(\"✅ 無完全重複的組合\")\n",
    "# else:\n",
    "#     print(f\"⚠️ 發現 {len(duplicated_rows)} 筆重複記錄：\")\n",
    "#     # display(duplicated_rows.head(40))\n",
    "#     # duplicated_rows.to_excel('duplicated_rows3.xlsx', index=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "13b4683f-89f8-4f97-9665-ac207480ee11",
   "metadata": {},
   "source": [
    "630B024C38H 的 mtl_desc1 有 0.5oz \n",
    "362S896C78H 的 mtl_desc1 有 0.5oz(Pin Lam),  0.45mm_1/1-HTE+7628*2+1080*1\n",
    "362S605A38N 的 mtl_desc1 是 362S605A38N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34f87ea-3521-496c-98da-64e793f49ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6c340c-c064-4bb1-9a66-3921821c7200",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
